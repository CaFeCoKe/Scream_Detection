{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demo.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1QBbZuZIzeavgFdXHBqpHv4A34_3F5130","authorship_tag":"ABX9TyP17r2KB2DYv5PJCKTnuj3Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!apt-get install portaudio19-dev    # import sounddevice <OSError: PortAudio library not found>\n","!pip install pyaudio==0.2.11\n","!pip install pyqtgraph\n","!pip install opencv-python==4.5.3.56"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znygQhZKsntW","executionInfo":{"status":"ok","timestamp":1647066527630,"user_tz":-540,"elapsed":18393,"user":{"displayName":"CaFe CoKe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKQbV_6mqL_VHCcbuNL4GHNUxGOJQBtuNsOFo3=s64","userId":"11886396836022920274"}},"outputId":"78cedabf-accd-424e-b51d-cc567c05839d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","portaudio19-dev is already the newest version (19.6.0-1).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n","Requirement already satisfied: pyaudio==0.2.11 in /usr/local/lib/python3.7/dist-packages (0.2.11)\n","Requirement already satisfied: pyqtgraph in /usr/local/lib/python3.7/dist-packages (0.12.4)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from pyqtgraph) (1.21.5)\n","Collecting opencv-python==4.5.3.56\n","  Downloading opencv_python-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[K     |████████████████████████████████| 49.9 MB 85 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.3.56) (1.21.5)\n","Installing collected packages: opencv-python\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed opencv-python-4.5.3.56\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lnJ0-vTsDnI"},"outputs":[],"source":["import sys\n","import numpy as np\n","\n","import pyaudio\n","\n","import pyqtgraph as pg\n","from PyQt5 import QtCore, uic\n","from PyQt5.QtGui import *\n","from PyQt5.QtWidgets import *\n","\n","import librosa\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","SAMPLING_RATE = 22050  # 음성데이터의 샘플링 레이트\n","CHUNK_SIZE = 22050  # 음성데이터를 불러올 때 한번에 22050개의 정수를 불러옴\n","form_class = uic.loadUiType(\"/content/drive/Othercomputers/내 컴퓨터/Scream_Detection/22.ui\")[0]\n","\n","\n","def feature_engineering_mel_spectrum(signal, sampling_rate, n_mels):\n","    cur_frame_temp = signal\n","\n","    # Mel Spectrograme 추출\n","    mel_spectrum_temp = librosa.feature.melspectrogram(\n","        y=cur_frame_temp,\n","        sr=sampling_rate,\n","        n_mels=n_mels,\n","        n_fft=2048,\n","        hop_length=512,\n","    )\n","    # power -> dB로 변환\n","    mel_spectrum_temp = librosa.core.power_to_db(mel_spectrum_temp)\n","    feature_vector = mel_spectrum_temp\n","    feature_vector = feature_vector[np.newaxis, :, :, np.newaxis]\n","    return feature_vector\n","\n","\n","class MicrophoneRecorder():\n","    def __init__(self, signal):\n","        self.signal = signal\n","        self.p = pyaudio.PyAudio()      # Pyaudio 인스턴스화\n","        # 음성 데이터 스트림 열기\n","        self.stream = self.p.open(\n","            format=pyaudio.paFloat32,   # 비트 깊이 = 32bit float\n","            channels=1,\n","            rate=SAMPLING_RATE,\n","            input=True,\n","            frames_per_buffer=CHUNK_SIZE\n","        )\n","\n","    def read(self):\n","        data = self.stream.read(CHUNK_SIZE, False)      # 음성 데이터를 문자열로 반환\n","        y = np.fromstring(data, 'float32')      # 문자열 -> 32bit float 넘파이 배열\n","        self.signal.emit(y)     # GUI로 값 전달\n","\n","    # 스트림 종료\n","    def close(self):\n","        print('멈춤')\n","        self.stream.stop_stream()\n","        self.stream.close()\n","        self.p.terminate()\n","\n","\n","class MyWindow(QMainWindow, form_class):\n","    read_collected = QtCore.pyqtSignal(np.ndarray)      # emit으로 GUI로 전달 될 값들의 매개변수 변수형을 기록\n","\n","    def __init__(self, model):\n","        super(MyWindow, self).__init__()\n","        self.setupUi(self)\n","        self.read_collected.connect(self.update)    # 시그널 및 슬롯 설정\n","\n","        self.model = model\n","\n","        # Bargraph\n","        pg.setConfigOptions(background='w', foreground='k')     # key-value 형태로 여러개 인자 사용 가능.\n","\n","        self.pw1 = pg.PlotWidget(title=\"BarGraph\")\n","        self.pw1.showGrid(x=True, y=True)\n","\n","        self.graph_box.addWidget(self.pw1)      # pw1을 위젯으로 등록\n","        self.pw1.setGeometry(4, 1, 10, 5)  # x, y, width, height\n","\n","        ticks = [list(zip(range(2), ('Environmental sound', 'Scream sound')))]\n","        xax = self.pw1.getAxis('bottom')        # bottom이라는 AxisItem 반환\n","        xax.setTicks(ticks)     # 표시할 눈금을 명시적으로 결정\n","        self.show()\n","\n","    def update(self, chunk):\n","        x = np.arange(2)\n","\n","        feature_vector = feature_engineering_mel_spectrum(chunk, SAMPLING_RATE, 64)\n","        feature_vector = torch.tensor(feature_vector).float()\n","        feature_vector = feature_vector.squeeze(3).unsqueeze(1)\n","        y_softmax = float(\n","            torch.sigmoid(self.model(feature_vector)).detach().numpy()\n","        )\n","\n","        if y_softmax > 0.5:\n","            pixmap = QPixmap(\"/content/drive/Othercomputers/내 컴퓨터/Scream_Detection/img/scream.png\")\n","            self.label_5.setPixmap(QPixmap(pixmap))\n","        else:\n","            pixmap = QPixmap(\"/content/drive/Othercomputers/내 컴퓨터/Scream_Detection/img/normal.png\")\n","            self.label_5.setPixmap(QPixmap(pixmap))\n","\n","        self.pw1.clear()\n","        barchart = pg.BarGraphItem(\n","            x=x, height=[1 - y_softmax, y_softmax], width=1, brush=(159, 191, 229)\n","        )\n","        self.pw1.addItem(barchart)\n","\n","\n","class CNN_model(nn.Module):\n","    def __init__(self):\n","        super(CNN_model, self).__init__()\n","\n","        # Convolution Layer\n","        self.conv1 = nn.Conv2d(1, 32, (64, 1))\n","        self.conv2 = nn.Conv2d(32, 64, (1, 9), stride=4)\n","\n","        # Nomalization Layer\n","        self.batch1 = nn.BatchNorm2d(32)\n","        self.batch2 = nn.BatchNorm2d(64)\n","\n","        # fully connected layer\n","        self.fc1 = nn.Linear(64*1*9, 1)\n","\n","        # 활성화 함수 ReLU\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","\n","        # Conv -> Nomalization -> ReLU -> Dropout\n","        x = self.conv1(x)\n","        x = self.batch1(x)\n","        x = self.relu(x)\n","        x = F.dropout2d(x, p=0.3, training=self.training)\n","\n","        # Conv -> Nomalization -> ReLU -> Dropout\n","        x = self.conv2(x)\n","        x = self.batch2(x)\n","        x = self.relu(x)\n","        x = F.dropout2d(x, p=0.3, training=self.training)\n","\n","        # Flatten -> Fully-connected\n","        x = x.view(-1, 64*1*9)\n","        x = self.fc1(x)\n","\n","        return x\n","\n","\n","model_dir = '/content/drive/Othercomputers/내 컴퓨터/Scream_Detection/test.pth'\n","model = CNN_model()\n","model.load_state_dict(torch.load(model_dir, map_location ='cpu'))\n","\n","app = QApplication(sys.argv)\n","myWindow = MyWindow(model=model)\n","mic = MicrophoneRecorder(myWindow.read_collected)\n","\n","interval = SAMPLING_RATE / CHUNK_SIZE\n","t = QtCore.QTimer()\n","t.timeout.connect(mic.read)\n","t.start(500)\n","\n","myWindow.show()\n","app.exec_()"]}]}